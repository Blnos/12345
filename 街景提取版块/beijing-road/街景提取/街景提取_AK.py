# -*- coding: utf-8 -*-
import re
import os
import csv
import time
import json
import requests
import glob
import traceback

# ==========================================
# é…ç½®åŒºåŸŸ
# ==========================================
# åœ¨æ­¤å¤„å¡«å…¥æ‚¨è´­ä¹°äº†é…é¢çš„ç™¾åº¦ AK
BAIDU_AK = "zwCZdF4xg9oU1FywO0WQH6mivt9MPLVs"  # æ‚¨çš„ AK


# ==========================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šå®˜æ–¹ API è½¬æ¢ç±» (å·²ä¼˜åŒ–)
# ==========================================

class BaiduCoordConverter:
    """
    ä½¿ç”¨ç™¾åº¦å®˜æ–¹ API è¿›è¡Œåæ ‡è½¬æ¢
    ä¼˜åŒ–ç­–ç•¥ï¼šä½¿ç”¨ geoconv/v1 æ¥å£ç›´æ¥ä» WGS84 è½¬ ç™¾åº¦å¢¨å¡æ‰˜ (to=6)
    ä¼˜åŠ¿ï¼šç²¾åº¦å®Œç¾ï¼Œä¸”ç›¸æ¯”ä¸¤æ­¥è½¬æ¢èŠ‚çœä¸€åŠé…é¢ã€‚
    """

    def __init__(self, ak):
        self.ak = ak
        # å®˜æ–¹æ–‡æ¡£ï¼šhttp://api.map.baidu.com/geoconv/v1/
        self.api_url = "http://api.map.baidu.com/geoconv/v1/"

    def wgs84_to_mc(self, lng, lat):
        """
        è¾“å…¥: WGS84 ç»çº¬åº¦ (GPSåŸå§‹åæ ‡)
        è¾“å‡º: ç™¾åº¦å¢¨å¡æ‰˜åæ ‡ (x, y) æ•´æ•°
        """
        params = {
            "coords": f"{lng},{lat}",
            "from": 1,  # 1 = WGS84
            "to": 6,  # 6 = ç™¾åº¦å¢¨å¡æ‰˜ (ç›´æ¥ç±³åˆ¶)
            "ak": self.ak,
            "output": "json"
        }

        try:
            # è¿™é‡Œçš„ timeout ç¨å¾®è®¾é•¿ä¸€ç‚¹ï¼Œé˜²æ­¢ç½‘ç»œæ³¢åŠ¨
            response = requests.get(self.api_url, params=params, timeout=5)

            # æ£€æŸ¥ HTTP çŠ¶æ€ç 
            if response.status_code != 200:
                print(f"      API HTTPé”™è¯¯: {response.status_code}")
                return None, None

            data = response.json()

            # status=0 ä»£è¡¨æˆåŠŸ
            if data.get("status") == 0:
                result = data["result"][0]
                # ç™¾åº¦å¢¨å¡æ‰˜é€šå¸¸å–æ•´æ•°å³å¯
                return int(result["x"]), int(result["y"])
            else:
                # status=210 ä»£è¡¨ IP æ ¡éªŒå¤±è´¥ï¼Œ240 ä»£è¡¨é…é¢ç”¨å°½ ç­‰
                print(f"      API ä¸šåŠ¡é”™è¯¯ç : {data.get('status')} - {data.get('message')}")
                return None, None

        except Exception as e:
            print(f"      API è¯·æ±‚å¼‚å¸¸: {e}")
            return None, None


# ==========================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šå·¥å…·å‡½æ•° (ä¿æŒä¸å˜)
# ==========================================

def write_csv(filepath, data, head=None):
    if head and not os.path.exists(filepath):
        data = [head] + data
    elif head:
        data = [head] + data
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    with open(filepath, mode='w', encoding='UTF-8-sig', newline='') as f:
        writer = csv.writer(f)
        for i in data:
            writer.writerow(i)


def read_csv(filepath):
    data = []
    if os.path.exists(filepath):
        with open(filepath, mode='r', encoding='utf-8') as f:
            lines = csv.reader(f)
            for line in lines:
                data.append(line)
        return data
    else:
        return []


def grab_img_baidu(_url):
    headers = {
        "Referer": "https://map.baidu.com/",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36"
    }
    try:
        response = requests.get(_url, headers=headers, timeout=10)
        if response.status_code == 200 and response.headers.get('Content-Type') == 'image/jpeg':
            return response.content
        return None
    except Exception:
        return None


def openUrl(_url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36"
    }
    try:
        response = requests.get(_url, headers=headers, timeout=10)
        if response.status_code == 200:
            return response.content
        return None
    except Exception:
        return None


def getPanoId(_mc_x, _mc_y):
    """
    é€šè¿‡å¢¨å¡æ‰˜åæ ‡æŸ¥è¯¢ Panoid
    """
    url = f"https://mapsv0.bdimg.com/?&qt=qsdata&x={_mc_x}&y={_mc_y}&l=17&action=0&mode=day&t=1530956939770"
    response = openUrl(url)
    if response is None:
        return None
    try:
        response_str = response.decode("utf8")
        # ä½¿ç”¨ JSON è§£ææ¯”æ­£åˆ™æ›´ç¨³å®š
        data = json.loads(response_str)
        if 'content' in data and 'id' in data['content']:
            return data['content']['id']
    except:
        pass
    return None


# ==========================================
# ä¸»ç¨‹åºå…¥å£
# ==========================================

if __name__ == "__main__":
    # åˆå§‹åŒ– API è½¬æ¢å™¨
    if not BAIDU_AK:
        print("âŒ è¯·å…ˆåœ¨ä»£ç é¡¶éƒ¨å¡«å…¥æ‚¨çš„ç™¾åº¦ AKï¼")
        exit()

    converter = BaiduCoordConverter(BAIDU_AK)
    print("âœ… API è½¬æ¢å™¨åˆå§‹åŒ–æˆåŠŸï¼Œå·²å¯ç”¨å®˜æ–¹ AK æ¨¡å¼ã€‚")

    current_dir = os.path.dirname(os.path.abspath(__file__))
    input_points_dir = os.path.join(current_dir, r'../è·¯ç½‘æå–/output_road_network/road_points')
    input_points_dir = os.path.normpath(input_points_dir)

    output_root_name = 'image_dir'
    base_output_dir = os.path.join(current_dir, output_root_name)
    base_error_dir = os.path.join(base_output_dir, 'error_points')

    csv_pattern = os.path.join(input_points_dir, "point_*.csv")
    csv_files = glob.glob(csv_pattern)

    if not csv_files:
        print(f"âŒ æœªæ‰¾åˆ°ä»»ä½•CSVæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {input_points_dir}")
        exit()

    print(f"ğŸ“‚ å‘ç° {len(csv_files)} ä¸ªä»»åŠ¡æ–‡ä»¶ï¼Œå‡†å¤‡å¼€å§‹å¤„ç†...\n")
    os.makedirs(base_error_dir, exist_ok=True)

    for index, csv_path in enumerate(csv_files):
        file_name = os.path.basename(csv_path)
        print(f"[{index + 1}/{len(csv_files)}] æ­£åœ¨è¯»å–æ–‡ä»¶: {file_name}")

        try:
            parts = file_name.split('_')
            street_name = parts[1] if len(parts) >= 2 else file_name.replace('.csv', '')
        except:
            street_name = "unknown_street"

        current_img_dir = os.path.join(base_output_dir, f"{street_name}_images")
        os.makedirs(current_img_dir, exist_ok=True)
        current_error_csv = os.path.join(base_error_dir, f"{street_name}_error.csv")

        data = read_csv(csv_path)
        if not data:
            continue

        header = data[0]
        data_rows = data[1:]

        filenames_exist = set()
        if os.path.exists(current_img_dir):
            for f in os.listdir(current_img_dir):
                if f.endswith('.png'):
                    filenames_exist.add(f)

        error_img = []
        headings = ['0', '90', '180', '270']

        # ç¼“å­˜ï¼šé¿å…åŒä¸€ä¸ªåæ ‡ç‚¹é‡å¤è°ƒç”¨ API æ‰£è´¹
        coord_cache = {}

        print(f"   >>> å¼€å§‹å¤„ç† {len(data_rows)} ä¸ªç‚¹...")

        for i, row in enumerate(data_rows):
            if (i + 1) % 20 == 0:
                print(f'      è¿›åº¦: {i + 1}/{len(data_rows)}')

            try:
                # ã€è¯·ç¡®è®¤CSVåˆ—æ˜¯å¦æ­£ç¡®ã€‘ å‡è®¾ï¼šID, Area, Lng, Lat
                longitude = row[2]
                latitude = row[3]
                Area = row[1]
                ID = row[0]
            except IndexError:
                continue

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            all_exist = True
            for heading in headings:
                img_name = f"{ID}_{Area}_{longitude}_{latitude}_{heading}_0.png"
                if img_name not in filenames_exist:
                    all_exist = False
                    break
            if all_exist:
                continue

            # -------------------------------------------------
            # æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨ AK è¿›è¡Œåæ ‡è½¬æ¢
            # -------------------------------------------------
            coord_key = f"{longitude}_{latitude}"

            if coord_key in coord_cache:
                mc_x, mc_y = coord_cache[coord_key]
            else:
                # è°ƒç”¨å®˜æ–¹ API
                mc_x, mc_y = converter.wgs84_to_mc(longitude, latitude)

                # å¦‚æœè½¬æ¢æˆåŠŸï¼Œå­˜å…¥ç¼“å­˜
                if mc_x is not None:
                    coord_cache[coord_key] = (mc_x, mc_y)
                    # ç¨å¾® sleep ä¸€ä¸‹ï¼Œè™½ç„¶å®˜æ–¹å¹¶å‘é«˜ï¼Œä½†ç¨³ä¸€ç‚¹æ›´å¥½
                    time.sleep(0.05)
                else:
                    # è½¬æ¢å¤±è´¥ï¼ˆå¯èƒ½æ˜¯åæ ‡éæ³•æˆ–é…é¢è€—å°½ï¼‰
                    error_img.append(row + ['API_Convert_Fail'])
                    continue

            # -------------------------------------------------
            # åç»­é€»è¾‘ä¿æŒä¸å˜ï¼šæ‹¿ Panoid -> ä¸‹è½½å›¾ç‰‡
            # -------------------------------------------------
            svid = getPanoId(mc_x, mc_y)
            if not svid:
                # print(f"      âŒ æ— è¡—æ™¯: {ID}")
                error_img.append(row + ['No_SV_ID'])
                continue

            for heading in headings:
                save_name = f"{ID}_{Area}_{longitude}_{latitude}_{heading}_0.png"
                save_file_abs = os.path.join(current_img_dir, save_name)

                if save_name in filenames_exist:
                    continue

                url = f'https://mapsv0.bdimg.com/?qt=pr3d&fovy=90&quality=100&panoid={svid}&heading={heading}&pitch=0&width=480&height=320'
                img_data = grab_img_baidu(url)

                if img_data:
                    with open(save_file_abs, "wb") as f:
                        f.write(img_data)
                    filenames_exist.add(save_name)
                    # print(f"      å·²ä¿å­˜: {save_name}")
                else:
                    error_img.append(row + [heading])

                # ä¸‹è½½é—´éš”
                time.sleep(0.2)

        if error_img:
            write_csv(current_error_csv, error_img, header + ['error_info'])
            print(f"   âš ï¸ {street_name} å®Œæˆï¼Œæœ‰ {len(error_img)} ä¸ªå¼‚å¸¸ã€‚")
        else:
            print(f"   âœ… {street_name} å…¨éƒ¨æˆåŠŸã€‚")

    print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæ¯•ï¼")
